{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8acc442-ce75-42be-8b49-b0a1be461d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "from scipy import stats\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de677b16-6eb3-4aff-863b-d4e5a71595d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarningsIVDataPipeline:\n",
    "    \"\"\"\n",
    "    Enhanced pipeline for detailed earnings IV analysis with focus on single-name studies\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, db_connection):\n",
    "        self.db = db_connection\n",
    "        self.data = {}\n",
    "        self.available_tables = None\n",
    "        self.analysis_results = {}\n",
    "        \n",
    "    # [Include all previous methods from original class - setup_optionm_tables, build_optionm_query, etc.]\n",
    "    # ... (keeping original methods for brevity, but they would all be included)\n",
    "\n",
    "    def setup_optionm_tables(self):\n",
    "        \"\"\"\n",
    "        Get available OptionMetrics tables\n",
    "        \"\"\"\n",
    "        if self.available_tables is None:\n",
    "            tables_df = self.db.raw_sql(\"\"\"\n",
    "                SELECT table_name\n",
    "                FROM information_schema.tables\n",
    "                WHERE table_schema = 'optionm'\n",
    "                ORDER BY table_name\n",
    "            \"\"\")\n",
    "            self.available_tables = set(tables_df['table_name'].str.lower())\n",
    "        return self.available_tables\n",
    "    \n",
    "    def build_optionm_query(self, table_base, start_date, end_date, fields, secids=None):\n",
    "        \"\"\"\n",
    "        Build OptionMetrics query using your existing query builder logic\n",
    "        \"\"\"\n",
    "        table_base = table_base.lower()\n",
    "        \n",
    "        # Match all tables starting with the given base (e.g. opprcd)\n",
    "        matching_tables = [t for t in self.available_tables if t.startswith(table_base)]\n",
    "        if not matching_tables:\n",
    "            return f\"Table '{table_base}' not found in OptionMetrics.\"\n",
    "        \n",
    "        # SECID filter\n",
    "        secid_filter = \"\"\n",
    "        if secids is not None:\n",
    "            if isinstance(secids, (list, tuple, set)):\n",
    "                secid_list = \", \".join(str(s) for s in secids)\n",
    "                secid_filter = f\"AND secid IN ({secid_list})\"\n",
    "            else:\n",
    "                secid_filter = f\"AND secid = {secids}\"\n",
    "        \n",
    "        # Determine year range\n",
    "        years = list(range(pd.to_datetime(start_date).year, pd.to_datetime(end_date).year + 1))\n",
    "         \n",
    "        # Case: non-suffixed (single) table (e.g., 'securd1')\n",
    "        if table_base in matching_tables:\n",
    "            return f\"\"\"\n",
    "    SELECT {', '.join(fields)}\n",
    "    FROM optionm.{table_base}\n",
    "    WHERE date BETWEEN '{start_date}' AND '{end_date}'\n",
    "    {secid_filter}\n",
    "            \"\"\".strip()\n",
    "        \n",
    "        # Case: year-suffixed tables (e.g., opprcd2014, hvold2015, etc.)\n",
    "        union_queries = []\n",
    "        for year in years:\n",
    "            table_year = f\"{table_base}{year}\"\n",
    "            if table_year in matching_tables:\n",
    "                query = f\"\"\"\n",
    "    SELECT {', '.join(fields)}\n",
    "    FROM optionm.{table_year}\n",
    "    WHERE date BETWEEN '{start_date}' AND '{end_date}'\n",
    "    {secid_filter}\n",
    "    \"\"\".strip()\n",
    "                union_queries.append(query)\n",
    "        \n",
    "        if not union_queries:\n",
    "            return f\"No available year-specific tables for '{table_base}' in range {years}.\"\n",
    "        \n",
    "        return \"\\nUNION ALL\\n\".join(union_queries)\n",
    "\n",
    "    def build_rdq_query_from_tickers(self, ticker_list, start_date, end_date):\n",
    "        \"\"\"\n",
    "        Build SQL query to fetch earnings report dates (rdq) for a list of tickers.\n",
    "        \"\"\"\n",
    "        if not ticker_list:\n",
    "            raise ValueError(\"You must provide at least one ticker.\")\n",
    "        \n",
    "        # Format tickers for SQL IN clause\n",
    "        formatted_tickers = ', '.join([f\"'{ticker}'\" for ticker in ticker_list])\n",
    "        \n",
    "        query = f\"\"\"\n",
    "        SELECT cusip,\n",
    "               tic as ticker,\n",
    "               datadate,\n",
    "               rdq as earnings_date,\n",
    "               fyearq,\n",
    "               fqtr\n",
    "        FROM comp.fundq\n",
    "        WHERE tic IN ({formatted_tickers})\n",
    "          AND rdq BETWEEN '{start_date}' AND '{end_date}'\n",
    "          AND rdq IS NOT NULL\n",
    "        ORDER BY tic, rdq;\n",
    "        \"\"\"\n",
    "        return query\n",
    "    \n",
    "    def build_secprd_query(self, secid_list, start_date, end_date):\n",
    "        \"\"\"\n",
    "        Build SQL query to fetch daily stock data from optionm.secprd for a list of SECIDs.\n",
    "        \"\"\"\n",
    "        if not secid_list:\n",
    "            raise ValueError(\"SECID list is empty.\")\n",
    "        \n",
    "        # Format SECIDs as numeric values, no quotes\n",
    "        formatted_secids = ', '.join([str(int(secid)) for secid in secid_list])\n",
    "        \n",
    "        query = f\"\"\"\n",
    "        SELECT *\n",
    "        FROM optionm.secprd\n",
    "        WHERE secid IN ({formatted_secids})\n",
    "          AND date BETWEEN '{start_date}' AND '{end_date}'\n",
    "        ORDER BY secid, date;\n",
    "        \"\"\"\n",
    "        return query\n",
    "    def get_securities_info(self, ticker_list):\n",
    "        \"\"\"\n",
    "        Get security information from OptionMetrics securd1 table\n",
    "        \"\"\"\n",
    "        print(\"Fetching security information from OptionMetrics...\")\n",
    "        \n",
    "        # Format tickers for SQL IN clause\n",
    "        formatted_tickers = ', '.join([f\"'{ticker}'\" for ticker in ticker_list])\n",
    "        \n",
    "        query = f\"\"\"\n",
    "        SELECT DISTINCT *\n",
    "        FROM optionm.securd1\n",
    "        WHERE ticker IN ({formatted_tickers})\n",
    "          AND exchange_d != 0\n",
    "        ORDER BY ticker\n",
    "        \"\"\"\n",
    "        \n",
    "        self.data['securities'] = self.db.raw_sql(query)\n",
    "        print(f\"Retrieved {len(self.data['securities'])} securities\")\n",
    "        \n",
    "        return self.data['securities']\n",
    "    \n",
    "    def get_earnings_dates(self, ticker_list, start_date='2023-01-01', end_date='2024-12-31'):\n",
    "        \"\"\"\n",
    "        Fetch earnings announcement dates using Compustat\n",
    "        \"\"\"\n",
    "        print(\"Fetching earnings announcement dates from Compustat...\")\n",
    "        \n",
    "        query = self.build_rdq_query_from_tickers(ticker_list, start_date, end_date)\n",
    "        \n",
    "        try:\n",
    "            self.data['earnings'] = self.db.raw_sql(query)\n",
    "            print(f\"Retrieved {len(self.data['earnings'])} earnings announcements\")\n",
    "            return self.data['earnings']\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching earnings data: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def get_option_data(self, secid_list, start_date='2023-01-01', end_date='2024-12-31'):\n",
    "        \"\"\"\n",
    "        Fetch option data from OptionMetrics using secids - NO SYNTHETIC DATA\n",
    "        \"\"\"\n",
    "        print(\"Fetching option data from OptionMetrics...\")\n",
    "        \n",
    "        # Setup available tables\n",
    "        self.setup_optionm_tables()\n",
    "        \n",
    "        # Define fields to select - using common OptionMetrics field names\n",
    "        fields = [\n",
    "            'date', 'secid', 'exdate', 'strike_price', 'cp_flag',\n",
    "            'best_bid', 'best_offer', 'open_interest',\n",
    "            'impl_volatility', 'delta', 'gamma', 'theta', 'vega', 'volume'\n",
    "        ]\n",
    "        \n",
    "        # Build query using your query builder\n",
    "        query = self.build_optionm_query('opprcd', start_date, end_date, fields, secid_list)\n",
    "        \n",
    "        if \"not found\" in query or \"No available\" in query:\n",
    "            print(f\"Query build failed: {query}\")\n",
    "            return None\n",
    "        \n",
    "        try:\n",
    "            print(\"Executing options query...\")\n",
    "            self.data['options'] = self.db.raw_sql(query)\n",
    "            \n",
    "            # Debug: Print column names to see what's available\n",
    "            print(f\"Available columns in options data: {list(self.data['options'].columns)}\")\n",
    "            \n",
    "            # Check for volume column variations\n",
    "            volume_field_candidates = ['volume', 'vol', 'contract_volume', 'opt_volume']\n",
    "            volume_col = None\n",
    "            for col_candidate in volume_field_candidates:\n",
    "                if col_candidate in self.data['options'].columns:\n",
    "                    volume_col = col_candidate\n",
    "                    break\n",
    "            \n",
    "            if volume_col and volume_col != 'volume':\n",
    "                print(f\"Found volume column: {volume_col}, renaming to 'volume'\")\n",
    "                self.data['options']['volume'] = self.data['options'][volume_col]\n",
    "            \n",
    "            print(f\"Retrieved {len(self.data['options'])} option records\")\n",
    "            return self.data['options']\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching options data: {e}\")\n",
    "            print(\"Attempting to query with minimal fields...\")\n",
    "            \n",
    "            # Fallback: try with minimal fields - NO SYNTHETIC DATA\n",
    "            minimal_fields = ['date', 'secid', 'exdate', 'strike_price', 'cp_flag', \n",
    "                            'best_bid', 'best_offer', 'impl_volatility']\n",
    "            \n",
    "            query = self.build_optionm_query('opprcd', start_date, end_date, minimal_fields, secid_list)\n",
    "            \n",
    "            try:\n",
    "                self.data['options'] = self.db.raw_sql(query)\n",
    "                print(f\"Retrieved {len(self.data['options'])} option records with minimal fields\")\n",
    "                print(\"Warning: Limited fields available - some analyses may not be possible\")\n",
    "                return self.data['options']\n",
    "            except Exception as e2:\n",
    "                print(f\"Fallback also failed: {e2}\")\n",
    "                return None\n",
    "    \n",
    "    def get_stock_prices(self, secid_list, start_date='2023-01-01', end_date='2024-12-31'):\n",
    "        \"\"\"\n",
    "        Get underlying stock prices from OptionMetrics secprd\n",
    "        \"\"\"\n",
    "        print(\"Fetching stock prices from OptionMetrics...\")\n",
    "        \n",
    "        query = self.build_secprd_query(secid_list, start_date, end_date)\n",
    "        \n",
    "        try:\n",
    "            self.data['stock_prices'] = self.db.raw_sql(query)\n",
    "            print(f\"Retrieved {len(self.data['stock_prices'])} stock price records\")\n",
    "            return self.data['stock_prices']\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching stock prices: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def merge_securities_earnings(self):\n",
    "        \"\"\"\n",
    "        Merge securities info with earnings data using ticker matching\n",
    "        \"\"\"\n",
    "        if 'securities' not in self.data or 'earnings' not in self.data:\n",
    "            print(\"Need both securities and earnings data\")\n",
    "            return None\n",
    "        \n",
    "        # Merge on ticker\n",
    "        merged = self.data['earnings'].merge(\n",
    "            self.data['securities'][['secid', 'ticker', 'cusip', 'issuer']], \n",
    "            on='ticker', \n",
    "            how='inner'\n",
    "        )\n",
    "        \n",
    "        self.data['earnings_securities'] = merged\n",
    "        print(f\"Merged {len(merged)} earnings-securities records\")\n",
    "        return merged\n",
    "    \n",
    "    def calculate_option_metrics(self):\n",
    "        \"\"\"\n",
    "        Calculate additional option metrics - ONLY WITH REAL DATA\n",
    "        \"\"\"\n",
    "        if 'options' not in self.data:\n",
    "            raise ValueError(\"Options data not loaded. Run get_option_data() first.\")\n",
    "        \n",
    "        df = self.data['options'].copy()\n",
    "        \n",
    "        # Convert dates to datetime objects\n",
    "        df['date'] = pd.to_datetime(df['date'])\n",
    "        df['exdate'] = pd.to_datetime(df['exdate'])\n",
    "        \n",
    "        # Calculate time to expiration in days\n",
    "        df['tte'] = (df['exdate'] - df['date']).dt.days\n",
    "        \n",
    "        # Initialize underlying_price columns\n",
    "        df['underlying_price'] = np.nan\n",
    "\n",
    "        # Merge with stock prices to get underlying prices\n",
    "        if 'stock_prices' in self.data and not self.data['stock_prices'].empty:\n",
    "            stock_df = self.data['stock_prices'].copy()\n",
    "            stock_df['date'] = pd.to_datetime(stock_df['date'])\n",
    "            \n",
    "            # Rename columns in stock_df BEFORE merging to avoid suffix issues\n",
    "            stock_df = stock_df.rename(columns={'close': 'underlying_price'})\n",
    "            \n",
    "            # Only merge if stock_df has the necessary columns after rename\n",
    "            if 'underlying_price' in stock_df.columns:\n",
    "                df = df.merge(stock_df[['date', 'secid', 'underlying_price']], \n",
    "                              on=['date', 'secid'], \n",
    "                              how='left',\n",
    "                              suffixes=('', '_stock')) \n",
    "            else:\n",
    "                print(\"Warning: stock_prices DataFrame is missing 'close' column. Cannot merge underlying price.\")\n",
    "        else:\n",
    "            print(\"Warning: No stock prices data available. Cannot calculate proper moneyness.\")\n",
    "            \n",
    "        # Calculate mid_price\n",
    "        if 'best_bid' in df.columns and 'best_offer' in df.columns:\n",
    "            df['mid_price'] = (df['best_bid'] + df['best_offer']) / 2\n",
    "        \n",
    "        # Only fill missing underlying prices with mid_price if both exist\n",
    "        if 'mid_price' in df.columns:\n",
    "            df['underlying_price'] = df['underlying_price'].fillna(df['mid_price'])\n",
    "\n",
    "        # Calculate moneyness: Keep your original calculation\n",
    "        df['moneyness'] = df['strike_price'] / 100000.0\n",
    "        \n",
    "        # Calculate bid-ask spread only if both bid and offer exist\n",
    "        if 'best_bid' in df.columns and 'best_offer' in df.columns:\n",
    "            df['bid_ask_spread'] = np.where(\n",
    "                df['best_bid'] > 0, \n",
    "                (df['best_offer'] - df['best_bid']) / df['best_bid'], \n",
    "                np.nan \n",
    "            )\n",
    "            df['bid_ask_spread'] = df['bid_ask_spread'].clip(lower=0) \n",
    "        \n",
    "        # Log moneyness - only if moneyness is valid\n",
    "        if 'moneyness' in df.columns:\n",
    "            df['log_moneyness'] = np.log(df['moneyness'].clip(lower=0.01)) \n",
    "        \n",
    "        self.data['options_enhanced'] = df\n",
    "        print(f\"Enhanced {len(df)} option records with calculated metrics\")\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def apply_data_filters(self, min_volume=10, max_bid_ask_spread=0.5, \n",
    "                           tte_range=(7, 60), moneyness_range=(0.8, 1.2)):\n",
    "        \"\"\"\n",
    "        Apply data quality filters - ONLY filter on available real data\n",
    "        \"\"\"\n",
    "        if 'options_enhanced' not in self.data:\n",
    "            self.calculate_option_metrics()\n",
    "        \n",
    "        df = self.data['options_enhanced'].copy()\n",
    "        initial_count = len(df)\n",
    "        \n",
    "        print(f\"Applying filters to {initial_count:,} records...\")\n",
    "        print(f\"Available columns: {list(df.columns)}\")\n",
    "        \n",
    "        # Apply filters conditionally based on available columns\n",
    "        \n",
    "        if 'volume' in df.columns:\n",
    "            df_before = len(df)\n",
    "            df = df[df['volume'].notna() & (df['volume'] >= min_volume)]\n",
    "            print(f\"  After Volume filter (>= {min_volume}): {len(df):,} records ({len(df)/df_before:.1%} retained)\")\n",
    "        \n",
    "        if 'bid_ask_spread' in df.columns:\n",
    "            df_before = len(df)\n",
    "            df = df[df['bid_ask_spread'].notna() & (df['bid_ask_spread'] <= max_bid_ask_spread)]\n",
    "            print(f\"  After Bid-ask spread filter (<= {max_bid_ask_spread}): {len(df):,} records ({len(df)/df_before:.1%} retained)\")\n",
    "        \n",
    "        if 'tte' in df.columns:\n",
    "            df_before = len(df)\n",
    "            df = df[(df['tte'] >= tte_range[0]) & (df['tte'] <= tte_range[1])]\n",
    "            print(f\"  After TTE filter ({tte_range[0]} <= tte <= {tte_range[1]}): {len(df):,} records ({len(df)/df_before:.1%} retained)\")\n",
    "        \n",
    "        if 'moneyness' in df.columns:\n",
    "            df_before = len(df)\n",
    "            df = df[(df['moneyness'] >= moneyness_range[0]) & (df['moneyness'] <= moneyness_range[1])]\n",
    "            print(f\"  After Moneyness filter ({moneyness_range[0]} <= moneyness <= {moneyness_range[1]}): {len(df):,} records ({len(df)/df_before:.1%} retained)\")\n",
    "        \n",
    "        # Only filter on real data columns\n",
    "        real_data_filters = [\n",
    "            ('vega', lambda x: x > 0),\n",
    "            ('best_bid', lambda x: x > 0),\n",
    "            ('best_offer', lambda x: x > 0),\n",
    "            ('impl_volatility', lambda x: x > 0)\n",
    "        ]\n",
    "        \n",
    "        for col_name, filter_func in real_data_filters:\n",
    "            if col_name in df.columns:\n",
    "                df_before = len(df)\n",
    "                df = df[df[col_name].notna() & df[col_name].apply(filter_func)]\n",
    "                print(f\"  After {col_name} filter: {len(df):,} records ({len(df)/df_before:.1%} retained)\")\n",
    "        \n",
    "        filtered_count = len(df)\n",
    "        print(f\"Filtered from {initial_count:,} to {filtered_count:,} records \"\n",
    "              f\"({filtered_count/initial_count:.1%} retention)\")\n",
    "        \n",
    "        self.data['options_filtered'] = df\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def merge_earnings_options(self, event_window_days=30):\n",
    "        \"\"\"\n",
    "        Merge earnings dates with option data using secid\n",
    "        \"\"\"\n",
    "        if 'earnings_securities' not in self.data or 'options_filtered' not in self.data:\n",
    "            print(\"Need both earnings_securities and options_filtered data\")\n",
    "            return None\n",
    "        \n",
    "        earnings = self.data['earnings_securities'].copy()\n",
    "        options = self.data['options_filtered'].copy()\n",
    "        \n",
    "        # Convert dates\n",
    "        earnings['earnings_date'] = pd.to_datetime(earnings['earnings_date'])\n",
    "        options['date'] = pd.to_datetime(options['date'])\n",
    "        \n",
    "        # Merge on secid\n",
    "        merged_data = []\n",
    "        \n",
    "        for _, earning in earnings.iterrows():\n",
    "            secid = earning['secid']\n",
    "            earnings_date = earning['earnings_date']\n",
    "            \n",
    "            # Get options data within event window\n",
    "            secid_options = options[\n",
    "                (options['secid'] == secid) &\n",
    "                (options['date'] >= earnings_date - timedelta(days=event_window_days)) &\n",
    "                (options['date'] <= earnings_date)\n",
    "            ].copy()\n",
    "            \n",
    "            if len(secid_options) > 0:\n",
    "                secid_options['earnings_date'] = earnings_date\n",
    "                secid_options['days_to_earnings'] = (earnings_date - secid_options['date']).dt.days\n",
    "                secid_options['ticker'] = earning['ticker']\n",
    "                merged_data.append(secid_options)\n",
    "        \n",
    "        if merged_data:\n",
    "            self.data['earnings_options'] = pd.concat(merged_data, ignore_index=True)\n",
    "            print(f\"Merged dataset contains {len(self.data['earnings_options'])} records\")\n",
    "        else:\n",
    "            print(\"No matching earnings-options data found\")\n",
    "            \n",
    "        return self.data.get('earnings_options')\n",
    "        \n",
    "    \n",
    "    def get_large_cap_universe(self, min_market_cap=1e9, min_option_volume=1000):\n",
    "        \"\"\"\n",
    "        Get universe of large cap stocks with sufficient option volume\n",
    "        \"\"\"\n",
    "        print(\"Building large cap universe with option volume filters...\")\n",
    "        \n",
    "        query = f\"\"\"\n",
    "        WITH market_caps AS (\n",
    "            SELECT DISTINCT s.secid, s.ticker, s.issuer,\n",
    "                   p.close * s.share_vol as market_cap,\n",
    "                   p.date\n",
    "            FROM optionm.securd1 s\n",
    "            JOIN optionm.secprd p ON s.secid = p.secid\n",
    "            WHERE s.exchange_d != 0\n",
    "              AND p.date >= '2023-01-01'\n",
    "              AND p.close * s.share_vol >= {min_market_cap}\n",
    "        ),\n",
    "        option_volumes AS (\n",
    "            SELECT secid, \n",
    "                   AVG(COALESCE(volume, 0)) as avg_daily_volume,\n",
    "                   COUNT(*) as trading_days\n",
    "            FROM optionm.opprcd2023\n",
    "            WHERE volume IS NOT NULL AND volume > 0\n",
    "            GROUP BY secid\n",
    "            HAVING AVG(COALESCE(volume, 0)) >= {min_option_volume}\n",
    "        )\n",
    "        SELECT DISTINCT m.secid, m.ticker, m.issuer, \n",
    "               AVG(m.market_cap) as avg_market_cap,\n",
    "               v.avg_daily_volume as avg_option_volume\n",
    "        FROM market_caps m\n",
    "        JOIN option_volumes v ON m.secid = v.secid\n",
    "        GROUP BY m.secid, m.ticker, m.issuer, v.avg_daily_volume\n",
    "        ORDER BY avg_market_cap DESC\n",
    "        LIMIT 200\n",
    "        \"\"\"\n",
    "        \n",
    "        try:\n",
    "            self.data['universe'] = self.db.raw_sql(query)\n",
    "            print(f\"Universe contains {len(self.data['universe'])} stocks\")\n",
    "            return self.data['universe']\n",
    "        except Exception as e:\n",
    "            print(f\"Error building universe: {e}\")\n",
    "            # Fallback to manual list\n",
    "            fallback_tickers = ['AAPL', 'MSFT', 'GOOGL', 'AMZN', 'TSLA', 'META', 'NVDA', 'JPM', 'V', 'UNH']\n",
    "            return self.get_securities_info(fallback_tickers)\n",
    "\n",
    "        def single_name_deep_dive(self, ticker, start_date='2023-01-01', end_date='2024-12-31', \n",
    "                             tte_focus=[14, 30, 45], moneyness_focus=[0.95, 1.0, 1.05]):\n",
    "            \"\"\"\n",
    "            Comprehensive single-name analysis focusing on specific TTM/moneyness points\n",
    "            \"\"\"\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"DEEP DIVE ANALYSIS: {ticker}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        # Get security info\n",
    "        securities = self.get_securities_info([ticker])\n",
    "        if len(securities) == 0:\n",
    "            print(f\"No security data found for {ticker}\")\n",
    "            return None\n",
    "            \n",
    "        secid = securities.iloc[0]['secid']\n",
    "        \n",
    "        # Get all data for this ticker\n",
    "        earnings = self.get_earnings_dates([ticker], start_date, end_date)\n",
    "        stock_prices = self.get_stock_prices([secid], start_date, end_date)\n",
    "        \n",
    "        # Enhanced options data query with more fields\n",
    "        options = self.get_enhanced_option_data([secid], start_date, end_date)\n",
    "        \n",
    "        if options is None or len(options) == 0:\n",
    "            print(f\"No options data found for {ticker}\")\n",
    "            return None\n",
    "        \n",
    "        # Calculate realized volatility\n",
    "        realized_vol = self.calculate_realized_volatility(stock_prices, windows=[5, 10, 21, 30])\n",
    "        \n",
    "        # Focus analysis on liquid options\n",
    "        liquid_options = self.filter_liquid_options(options, tte_focus, moneyness_focus)\n",
    "        \n",
    "        # Merge with earnings\n",
    "        if earnings is not None and len(earnings) > 0:\n",
    "            earnings_options = self.merge_earnings_with_focused_options(\n",
    "                earnings, liquid_options, event_window=45\n",
    "            )\n",
    "        else:\n",
    "            earnings_options = liquid_options.copy()\n",
    "            earnings_options['earnings_date'] = None\n",
    "            earnings_options['days_to_earnings'] = None\n",
    "        \n",
    "        # Store results\n",
    "        analysis_key = f\"{ticker}_analysis\"\n",
    "        self.analysis_results[analysis_key] = {\n",
    "            'ticker': ticker,\n",
    "            'securities': securities,\n",
    "            'earnings': earnings,\n",
    "            'stock_prices': stock_prices,\n",
    "            'realized_vol': realized_vol,\n",
    "            'options': options,\n",
    "            'liquid_options': liquid_options,\n",
    "            'earnings_options': earnings_options\n",
    "        }\n",
    "        \n",
    "        # Generate comprehensive plots\n",
    "        self.plot_single_name_analysis(ticker, analysis_key)\n",
    "        \n",
    "        # Volume analysis\n",
    "        self.analyze_option_volume_vs_stock_adv(ticker, analysis_key)\n",
    "        \n",
    "        # Volatility surface analysis\n",
    "        self.analyze_pre_earnings_surface(ticker, analysis_key)\n",
    "        \n",
    "        return analysis_key\n",
    "    \n",
    "    def get_enhanced_option_data(self, secid_list, start_date, end_date):\n",
    "        \"\"\"\n",
    "        Get enhanced options data with additional calculated fields\n",
    "        \"\"\"\n",
    "        options = self.get_option_data(secid_list, start_date, end_date)\n",
    "        if options is None:\n",
    "            return None\n",
    "            \n",
    "        # Enhanced calculations\n",
    "        options = self.calculate_option_metrics()\n",
    "        \n",
    "        # Add more derived fields\n",
    "        df = options.copy()\n",
    "        \n",
    "        # Option notional value\n",
    "        if 'mid_price' in df.columns:\n",
    "            df['notional'] = df['mid_price'] * 100  # Standard option multiplier\n",
    "        \n",
    "        # Vega-weighted IV (if vega available)\n",
    "        if 'vega' in df.columns:\n",
    "            df['vega_weighted_iv'] = df['impl_volatility'] * df['vega']\n",
    "        \n",
    "        # Distance from ATM\n",
    "        if 'moneyness' in df.columns:\n",
    "            df['atm_distance'] = np.abs(np.log(df['moneyness']))\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def calculate_realized_volatility(self, stock_prices, windows=[5, 10, 21, 30]):\n",
    "        \"\"\"\n",
    "        Calculate realized volatility using multiple estimators and windows\n",
    "        \"\"\"\n",
    "        if stock_prices is None or len(stock_prices) == 0:\n",
    "            return None\n",
    "            \n",
    "        df = stock_prices.copy()\n",
    "        df['date'] = pd.to_datetime(df['date'])\n",
    "        df = df.sort_values('date')\n",
    "        \n",
    "        # Calculate returns\n",
    "        df['returns'] = np.log(df['close'] / df['close'].shift(1))\n",
    "        \n",
    "        realized_vol_data = {}\n",
    "        \n",
    "        for window in windows:\n",
    "            # Standard realized volatility\n",
    "            df[f'realized_vol_{window}d'] = df['returns'].rolling(window=window).std() * np.sqrt(252)\n",
    "            \n",
    "            # Exponentially weighted\n",
    "            df[f'ewm_vol_{window}d'] = df['returns'].ewm(span=window).std() * np.sqrt(252)\n",
    "            \n",
    "            # Parkinson estimator (if OHLC available)\n",
    "            if all(col in df.columns for col in ['high', 'low', 'open']):\n",
    "                hl_ratio = np.log(df['high'] / df['low'])\n",
    "                df[f'parkinson_vol_{window}d'] = np.sqrt(\n",
    "                    hl_ratio.rolling(window=window).apply(lambda x: np.sum(x**2) / len(x)) * 252\n",
    "                )\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def filter_liquid_options(self, options, tte_focus, moneyness_focus, \n",
    "                             min_volume=10, max_spread=0.3):\n",
    "        \"\"\"\n",
    "        Filter for liquid options around focal points\n",
    "        \"\"\"\n",
    "        df = options.copy()\n",
    "        \n",
    "        # TTE filter - within range of focus points\n",
    "        tte_ranges = [(tte-7, tte+7) for tte in tte_focus]\n",
    "        tte_mask = pd.Series(False, index=df.index)\n",
    "        for low, high in tte_ranges:\n",
    "            tte_mask |= (df['tte'] >= low) & (df['tte'] <= high)\n",
    "        \n",
    "        # Moneyness filter - within range of focus points\n",
    "        if 'moneyness' in df.columns:\n",
    "            money_ranges = [(money-0.05, money+0.05) for money in moneyness_focus]\n",
    "            money_mask = pd.Series(False, index=df.index)\n",
    "            for low, high in money_ranges:\n",
    "                money_mask |= (df['moneyness'] >= low) & (df['moneyness'] <= high)\n",
    "        else:\n",
    "            money_mask = pd.Series(True, index=df.index)\n",
    "        \n",
    "        # Volume and spread filters\n",
    "        volume_mask = pd.Series(True, index=df.index)\n",
    "        if 'volume' in df.columns:\n",
    "            volume_mask = df['volume'] >= min_volume\n",
    "            \n",
    "        spread_mask = pd.Series(True, index=df.index)\n",
    "        if 'bid_ask_spread' in df.columns:\n",
    "            spread_mask = df['bid_ask_spread'] <= max_spread\n",
    "        \n",
    "        # Combine filters\n",
    "        final_mask = tte_mask & money_mask & volume_mask & spread_mask\n",
    "        \n",
    "        print(f\"Liquidity filtering: {len(df)} -> {final_mask.sum()} options\")\n",
    "        return df[final_mask].copy()\n",
    "    \n",
    "    def merge_earnings_with_focused_options(self, earnings, options, event_window=45):\n",
    "        \"\"\"\n",
    "        Merge earnings with options data, focusing on pre-earnings period\n",
    "        \"\"\"\n",
    "        if earnings is None or len(earnings) == 0:\n",
    "            return options\n",
    "            \n",
    "        earnings['earnings_date'] = pd.to_datetime(earnings['earnings_date'])\n",
    "        options['date'] = pd.to_datetime(options['date'])\n",
    "        \n",
    "        merged_data = []\n",
    "        \n",
    "        for _, earning in earnings.iterrows():\n",
    "            secid = earning['secid']\n",
    "            earnings_date = earning['earnings_date']\n",
    "            \n",
    "            # Get options in event window (focusing on pre-earnings)\n",
    "            event_options = options[\n",
    "                (options['secid'] == secid) &\n",
    "                (options['date'] >= earnings_date - timedelta(days=event_window)) &\n",
    "                (options['date'] <= earnings_date + timedelta(days=5))  # Small post window\n",
    "            ].copy()\n",
    "            \n",
    "            if len(event_options) > 0:\n",
    "                event_options['earnings_date'] = earnings_date\n",
    "                event_options['days_to_earnings'] = (earnings_date - event_options['date']).dt.days\n",
    "                event_options['pre_post_earnings'] = np.where(\n",
    "                    event_options['days_to_earnings'] >= 0, 'pre', 'post'\n",
    "                )\n",
    "                merged_data.append(event_options)\n",
    "        \n",
    "        if merged_data:\n",
    "            return pd.concat(merged_data, ignore_index=True)\n",
    "        else:\n",
    "            return options.copy()\n",
    "    \n",
    "    def plot_single_name_analysis(self, ticker, analysis_key):\n",
    "        \"\"\"\n",
    "        Comprehensive plotting for single name analysis\n",
    "        \"\"\"\n",
    "        data = self.analysis_results[analysis_key]\n",
    "        \n",
    "        fig = plt.figure(figsize=(20, 16))\n",
    "        \n",
    "        # 1. Stock price and realized volatility\n",
    "        ax1 = plt.subplot(3, 3, 1)\n",
    "        if data['stock_prices'] is not None:\n",
    "            stock_df = data['stock_prices']\n",
    "            ax1.plot(pd.to_datetime(stock_df['date']), stock_df['close'], 'b-', linewidth=1)\n",
    "            ax1.set_title(f'{ticker} Stock Price')\n",
    "            ax1.set_ylabel('Price ($)')\n",
    "            \n",
    "            # Mark earnings dates\n",
    "            if data['earnings'] is not None:\n",
    "                for _, earning in data['earnings'].iterrows():\n",
    "                    ax1.axvline(pd.to_datetime(earning['earnings_date']), \n",
    "                               color='red', alpha=0.7, linestyle='--')\n",
    "        \n",
    "        # 2. Realized volatility comparison\n",
    "        ax2 = plt.subplot(3, 3, 2)\n",
    "        if data['realized_vol'] is not None:\n",
    "            rv_df = data['realized_vol']\n",
    "            rv_df['date'] = pd.to_datetime(rv_df['date'])\n",
    "            \n",
    "            # Plot different estimators\n",
    "            for col in rv_df.columns:\n",
    "                if 'vol_' in col and '21d' in col:  # Focus on 21-day window\n",
    "                    if 'realized' in col:\n",
    "                        ax2.plot(rv_df['date'], rv_df[col], label='Standard', alpha=0.8)\n",
    "                    elif 'ewm' in col:\n",
    "                        ax2.plot(rv_df['date'], rv_df[col], label='EWM', alpha=0.8)\n",
    "                    elif 'parkinson' in col:\n",
    "                        ax2.plot(rv_df['date'], rv_df[col], label='Parkinson', alpha=0.8)\n",
    "            \n",
    "            ax2.set_title('Realized Volatility (21d)')\n",
    "            ax2.set_ylabel('Annualized Vol')\n",
    "            ax2.legend()\n",
    "            \n",
    "            # Mark earnings\n",
    "            if data['earnings'] is not None:\n",
    "                for _, earning in data['earnings'].iterrows():\n",
    "                    ax2.axvline(pd.to_datetime(earning['earnings_date']), \n",
    "                               color='red', alpha=0.7, linestyle='--')\n",
    "        \n",
    "        # 3. Implied vs Realized Volatility\n",
    "        ax3 = plt.subplot(3, 3, 3)\n",
    "        if data['earnings_options'] is not None and data['realized_vol'] is not None:\n",
    "            options_df = data['earnings_options']\n",
    "            rv_df = data['realized_vol']\n",
    "            \n",
    "            # Daily average IV\n",
    "            daily_iv = options_df.groupby('date')['impl_volatility'].mean()\n",
    "            \n",
    "            # Merge with realized vol\n",
    "            rv_df_daily = rv_df.set_index('date')['realized_vol_21d']\n",
    "            \n",
    "            common_dates = daily_iv.index.intersection(rv_df_daily.index)\n",
    "            if len(common_dates) > 0:\n",
    "                ax3.scatter(rv_df_daily[common_dates], daily_iv[common_dates], \n",
    "                           alpha=0.6, s=20)\n",
    "                \n",
    "                # 45-degree line\n",
    "                min_val = min(rv_df_daily[common_dates].min(), daily_iv[common_dates].min())\n",
    "                max_val = max(rv_df_daily[common_dates].max(), daily_iv[common_dates].max())\n",
    "                ax3.plot([min_val, max_val], [min_val, max_val], 'r--', alpha=0.7)\n",
    "                \n",
    "                ax3.set_xlabel('Realized Vol (21d)')\n",
    "                ax3.set_ylabel('Implied Vol')\n",
    "                ax3.set_title('IV vs RV Scatter')\n",
    "        \n",
    "        # 4. Volatility surface evolution\n",
    "        ax4 = plt.subplot(3, 3, 4)\n",
    "        if data['liquid_options'] is not None:\n",
    "            self.plot_volatility_surface_evolution(data['liquid_options'], ax4)\n",
    "        \n",
    "        # 5. Volume analysis\n",
    "        ax5 = plt.subplot(3, 3, 5)\n",
    "        if data['liquid_options'] is not None:\n",
    "            volume_data = data['liquid_options']\n",
    "            if 'volume' in volume_data.columns:\n",
    "                daily_volume = volume_data.groupby('date')['volume'].sum()\n",
    "                ax5.plot(daily_volume.index, daily_volume.values, 'g-', alpha=0.7)\n",
    "                ax5.set_title('Daily Option Volume')\n",
    "                ax5.set_ylabel('Contracts')\n",
    "        \n",
    "        # 6. Pre-earnings IV term structure\n",
    "        ax6 = plt.subplot(3, 3, 6)\n",
    "        if data['earnings_options'] is not None:\n",
    "            pre_earnings = data['earnings_options'][\n",
    "                data['earnings_options']['pre_post_earnings'] == 'pre'\n",
    "            ]\n",
    "            if len(pre_earnings) > 0:\n",
    "                # Average IV by TTE for pre-earnings period\n",
    "                ts_data = pre_earnings.groupby('tte')['impl_volatility'].mean()\n",
    "                ax6.plot(ts_data.index, ts_data.values, 'bo-', markersize=4)\n",
    "                ax6.set_xlabel('Days to Expiration')\n",
    "                ax6.set_ylabel('Implied Volatility')\n",
    "                ax6.set_title('Pre-Earnings Term Structure')\n",
    "        \n",
    "        # 7. Earnings effect on IV\n",
    "        ax7 = plt.subplot(3, 3, 7)\n",
    "        if data['earnings_options'] is not None:\n",
    "            self.plot_earnings_iv_evolution(data['earnings_options'], ax7)\n",
    "        \n",
    "        # 8. Moneyness smile\n",
    "        ax8 = plt.subplot(3, 3, 8)\n",
    "        if data['liquid_options'] is not None and 'moneyness' in data['liquid_options'].columns:\n",
    "            self.plot_volatility_smile(data['liquid_options'], ax8)\n",
    "        \n",
    "        # 9. Summary statistics\n",
    "        ax9 = plt.subplot(3, 3, 9)\n",
    "        self.plot_summary_statistics(data, ax9)\n",
    "        \n",
    "        plt.suptitle(f'{ticker} - Comprehensive Analysis', fontsize=16, y=0.98)\n",
    "        plt.tight_layout()\n",
    "        plt.subplots_adjust(top=0.94)\n",
    "        plt.show()\n",
    "    \n",
    "    def plot_volatility_surface_evolution(self, options_df, ax):\n",
    "        \"\"\"Plot how volatility surface evolves over time\"\"\"\n",
    "        # Focus on recent data and create surface snapshots\n",
    "        if 'moneyness' not in options_df.columns:\n",
    "            ax.text(0.5, 0.5, 'No moneyness data', ha='center', va='center', transform=ax.transAxes)\n",
    "            return\n",
    "            \n",
    "        # Take snapshots at different dates\n",
    "        dates = sorted(options_df['date'].unique())[-10:]  # Last 10 trading days\n",
    "        \n",
    "        for i, date in enumerate(dates[::3]):  # Every 3rd date to avoid clutter\n",
    "            day_data = options_df[options_df['date'] == date]\n",
    "            if len(day_data) < 5:\n",
    "                continue\n",
    "                \n",
    "            # Group by moneyness and TTE\n",
    "            surface = day_data.groupby(['moneyness', 'tte'])['impl_volatility'].mean().reset_index()\n",
    "            \n",
    "            # Plot for a specific TTE (e.g., around 30 days)\n",
    "            tte_slice = surface[(surface['tte'] >= 25) & (surface['tte'] <= 35)]\n",
    "            if len(tte_slice) > 2:\n",
    "                color = plt.cm.viridis(i / len(dates[::3]))\n",
    "                ax.plot(tte_slice['moneyness'], tte_slice['impl_volatility'], \n",
    "                       'o-', color=color, alpha=0.7, markersize=3,\n",
    "                       label=f'{pd.to_datetime(date).strftime(\"%m/%d\")}')\n",
    "        \n",
    "        ax.set_xlabel('Moneyness')\n",
    "        ax.set_ylabel('Implied Volatility')\n",
    "        ax.set_title('IV Surface Evolution (30d TTE)')\n",
    "        if ax.get_legend_handles_labels()[0]:\n",
    "            ax.legend(fontsize=8)\n",
    "    \n",
    "    def plot_earnings_iv_evolution(self, earnings_options, ax):\n",
    "        \"\"\"Plot how IV evolves around earnings\"\"\"\n",
    "        if 'days_to_earnings' not in earnings_options.columns:\n",
    "            return\n",
    "            \n",
    "        # Average IV by days to earnings\n",
    "        iv_evolution = earnings_options.groupby('days_to_earnings')['impl_volatility'].agg([\n",
    "            'mean', 'std', 'count'\n",
    "        ]).reset_index()\n",
    "        \n",
    "        # Filter for sufficient observations\n",
    "        iv_evolution = iv_evolution[iv_evolution['count'] >= 3]\n",
    "        \n",
    "        if len(iv_evolution) > 0:\n",
    "            ax.errorbar(iv_evolution['days_to_earnings'], iv_evolution['mean'],\n",
    "                       yerr=iv_evolution['std'], marker='o', capsize=3, capthick=1, alpha=0.8)\n",
    "            ax.axvline(x=0, color='red', linestyle='--', alpha=0.7, label='Earnings Date')\n",
    "            ax.set_xlabel('Days to Earnings')\n",
    "            ax.set_ylabel('Implied Volatility')\n",
    "            ax.set_title('IV Evolution Around Earnings')\n",
    "            ax.legend()\n",
    "    \n",
    "    def plot_volatility_smile(self, options_df, ax):\n",
    "        \"\"\"Plot volatility smile\"\"\"\n",
    "        if 'moneyness' not in options_df.columns:\n",
    "            return\n",
    "            \n",
    "        # Focus on short-term options (7-45 days)\n",
    "        short_term = options_df[(options_df['tte'] >= 7) & (options_df['tte'] <= 45)]\n",
    "        \n",
    "        if len(short_term) == 0:\n",
    "            return\n",
    "            \n",
    "        # Group by moneyness bins\n",
    "        moneyness_bins = pd.cut(short_term['moneyness'], bins=15)\n",
    "        smile_data = short_term.groupby(moneyness_bins)['impl_volatility'].agg([\n",
    "            'mean', 'count'\n",
    "        ]).reset_index()\n",
    "        \n",
    "        # Filter for sufficient observations\n",
    "        smile_data = smile_data[smile_data['count'] >= 3]\n",
    "        \n",
    "        if len(smile_data) > 0:\n",
    "            moneyness_centers = smile_data['moneyness'].apply(lambda x: x.mid)\n",
    "            ax.plot(moneyness_centers, smile_data['mean'], 'bo-', markersize=4)\n",
    "            ax.set_xlabel('Moneyness')\n",
    "            ax.set_ylabel('Implied Volatility')\n",
    "            ax.set_title('Volatility Smile (7-45d)')\n",
    "    \n",
    "    def plot_summary_statistics(self, data, ax):\n",
    "        \"\"\"Plot key summary statistics\"\"\"\n",
    "        ax.axis('off')\n",
    "        \n",
    "        # Gather key stats\n",
    "        stats_text = []\n",
    "        \n",
    "        if data['earnings'] is not None:\n",
    "            stats_text.append(f\"Earnings Events: {len(data['earnings'])}\")\n",
    "        \n",
    "        if data['liquid_options'] is not None:\n",
    "            total_contracts = len(data['liquid_options'])\n",
    "            stats_text.append(f\"Liquid Options: {total_contracts:,}\")\n",
    "            \n",
    "            if 'volume' in data['liquid_options'].columns:\n",
    "                avg_volume = data['liquid_options']['volume'].mean()\n",
    "                stats_text.append(f\"Avg Volume: {avg_volume:.0f}\")\n",
    "            \n",
    "            if 'impl_volatility' in data['liquid_options'].columns:\n",
    "                avg_iv = data['liquid_options']['impl_volatility'].mean()\n",
    "                std_iv = data['liquid_options']['impl_volatility'].std()\n",
    "                stats_text.append(f\"Avg IV: {avg_iv:.3f} Â± {std_iv:.3f}\")\n",
    "        \n",
    "        if data['realized_vol'] is not None and 'realized_vol_21d' in data['realized_vol'].columns:\n",
    "            avg_rv = data['realized_vol']['realized_vol_21d'].mean()\n",
    "            stats_text.append(f\"Avg RV (21d): {avg_rv:.3f}\")\n",
    "        \n",
    "        # Display stats\n",
    "        y_pos = 0.9\n",
    "        for stat in stats_text:\n",
    "            ax.text(0.1, y_pos, stat, transform=ax.transAxes, fontsize=10, \n",
    "                   verticalalignment='top')\n",
    "            y_pos -= 0.15\n",
    "        \n",
    "        ax.set_title('Summary Statistics')\n",
    "    \n",
    "    def analyze_option_volume_vs_stock_adv(self, ticker, analysis_key):\n",
    "        \"\"\"\n",
    "        Analyze option volume relative to stock average daily volume\n",
    "        \"\"\"\n",
    "        data = self.analysis_results[analysis_key]\n",
    "        \n",
    "        if data['liquid_options'] is None or data['stock_prices'] is None:\n",
    "            print(\"Insufficient data for volume analysis\")\n",
    "            return\n",
    "        \n",
    "        # Calculate stock ADV\n",
    "        stock_df = data['stock_prices']\n",
    "        if 'volume' in stock_df.columns:\n",
    "            stock_adv = stock_df['volume'].mean()\n",
    "        else:\n",
    "            print(\"No stock volume data available\")\n",
    "            return\n",
    "        \n",
    "        options_df = data['liquid_options']\n",
    "        \n",
    "        # Calculate daily option volume and notional\n",
    "        if 'volume' in options_df.columns:\n",
    "            daily_option_volume = options_df.groupby('date').agg({\n",
    "                'volume': 'sum',\n",
    "                'notional': 'sum' if 'notional' in options_df.columns else lambda x: 0\n",
    "            }).reset_index()\n",
    "            \n",
    "            # Option volume as % of stock ADV\n",
    "            daily_option_volume['volume_ratio'] = daily_option_volume['volume'] / stock_adv * 100\n",
    "            \n",
    "            print(f\"\\n{ticker} Volume Analysis:\")\n",
    "            print(f\"Stock ADV: {stock_adv:,.0f}\")\n",
    "            print(f\"Avg Daily Option Volume: {daily_option_volume['volume'].mean():,.0f}\")\n",
    "            print(f\"Option/Stock Volume Ratio: {daily_option_volume['volume_ratio'].mean():.1f}%\")\n",
    "            \n",
    "            # Plot volume comparison\n",
    "            fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 8))\n",
    "            \n",
    "            # Daily option volume\n",
    "            ax1.bar(daily_option_volume['date'], daily_option_volume['volume'], \n",
    "                   alpha=0.7, color='blue')\n",
    "            ax1.axhline(y=daily_option_volume['volume'].mean(), color='red', \n",
    "                       linestyle='--', alpha=0.7, label='Average')\n",
    "            ax1.set_ylabel('Option Volume (Contracts)')\n",
    "            ax1.set_title(f'{ticker} Daily Option Volume')\n",
    "            ax1.legend()\n",
    "            \n",
    "            # Volume ratio\n",
    "            ax2.plot(daily_option_volume['date'], daily_option_volume['volume_ratio'], \n",
    "                    'go-', markersize=4, alpha=0.7)\n",
    "            ax2.axhline(y=daily_option_volume['volume_ratio'].mean(), color='red', \n",
    "                       linestyle='--', alpha=0.7)\n",
    "            ax2.set_ylabel('Option/Stock Volume (%)')\n",
    "            ax2.set_xlabel('Date')\n",
    "            ax2.set_title('Option Volume as % of Stock ADV')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "    \n",
    "    def analyze_pre_earnings_surface(self, ticker, analysis_key):\n",
    "            \"\"\"\n",
    "            Detailed analysis of volatility surface before earnings\n",
    "            \"\"\"\n",
    "            data = self.analysis_results[analysis_key]\n",
    "            \n",
    "            if data['earnings_options'] is None:\n",
    "                print(\"No earnings-options data for surface analysis\")\n",
    "                return\n",
    "            \n",
    "            earnings_df = data['earnings_options']\n",
    "            \n",
    "            # Focus on pre-earnings period (1-5 days before)\n",
    "            pre_earnings = earnings_df[\n",
    "                (earnings_df['days_to_earnings'] >= 1) & \n",
    "                (earnings_df['days_to_earnings'] <= 5)\n",
    "            ]\n",
    "            \n",
    "            if len(pre_earnings) == 0:\n",
    "                print(\"No pre-earnings options data found\")\n",
    "                return\n",
    "            \n",
    "            print(f\"\\n{ticker} Pre-Earnings Surface Analysis:\")\n",
    "            print(f\"Options in 1-5 days before earnings: {len(pre_earnings)}\")\n",
    "            \n",
    "            # Create surface plot\n",
    "            fig = plt.figure(figsize=(15, 10))\n",
    "            \n",
    "            # 3D Surface plot\n",
    "            ax1 = fig.add_subplot(221, projection='3d')\n",
    "            \n",
    "            if all(col in pre_earnings.columns for col in ['moneyness', 'tte', 'impl_volatility']):\n",
    "                # Create surface data\n",
    "                surface_data = pre_earnings.groupby(['moneyness', 'tte'])['impl_volatility'].mean().reset_index()\n",
    "                \n",
    "                if len(surface_data) > 10:\n",
    "                    # Create meshgrid\n",
    "                    moneyness_unique = sorted(surface_data['moneyness'].unique())\n",
    "                    tte_unique = sorted(surface_data['tte'].unique())\n",
    "                    \n",
    "                    X, Y = np.meshgrid(moneyness_unique[:10], tte_unique[:10])  # Limit size\n",
    "                    Z = np.zeros_like(X)\n",
    "                    \n",
    "                    for i, tte in enumerate(tte_unique[:10]):\n",
    "                        for j, moneyness in enumerate(moneyness_unique[:10]):\n",
    "                            iv_val = surface_data[\n",
    "                                (surface_data['tte'] == tte) & \n",
    "                                (surface_data['moneyness'] == moneyness)\n",
    "                            ]['impl_volatility']\n",
    "                            Z[i, j] = iv_val.iloc[0] if len(iv_val) > 0 else np.nan\n",
    "                    \n",
    "                    # Remove NaN values\n",
    "                    mask = ~np.isnan(Z)\n",
    "                    if mask.sum() > 0:\n",
    "                        ax1.plot_surface(X, Y, Z, alpha=0.7, cmap='viridis')\n",
    "                        ax1.set_xlabel('Moneyness')\n",
    "                        ax1.set_ylabel('Time to Expiration')\n",
    "                        ax1.set_zlabel('Implied Volatility')\n",
    "                        ax1.set_title('Pre-Earnings IV Surface')\n",
    "            \n",
    "            # 2D slices\n",
    "            ax2 = fig.add_subplot(222)\n",
    "            # ATM term structure\n",
    "            atm_data = pre_earnings[\n",
    "                (pre_earnings['moneyness'] >= 0.95) & \n",
    "                (pre_earnings['moneyness'] <= 1.05)\n",
    "            ]\n",
    "            if len(atm_data) > 0:\n",
    "                ts_data = atm_data.groupby('tte')['impl_volatility'].mean()\n",
    "                ax2.plot(ts_data.index, ts_data.values, 'bo-', markersize=5)\n",
    "                ax2.set_xlabel('Days to Expiration')\n",
    "                ax2.set_ylabel('Implied Volatility')\n",
    "                ax2.set_title('ATM Term Structure (Pre-Earnings)')\n",
    "            \n",
    "            # Volatility smile for specific TTE\n",
    "            ax3 = fig.add_subplot(223)\n",
    "            short_tte = pre_earnings[(pre_earnings['tte'] >= 14) & (pre_earnings['tte'] <= 30)]\n",
    "            if len(short_tte) > 0:\n",
    "                smile_data = short_tte.groupby('moneyness')['impl_volatility'].mean()\n",
    "                ax3.plot(smile_data.index, smile_data.values, 'ro-', markersize=4)\n",
    "                ax3.set_xlabel('Moneyness')\n",
    "                ax3.set_ylabel('Implied Volatility')\n",
    "                ax3.set_title('Volatility Smile (14-30 DTE)')\n",
    "                ax3.axvline(x=1.0, color='black', linestyle='--', alpha=0.5, label='ATM')\n",
    "                ax3.legend()\n",
    "            \n",
    "            # Volume and Open Interest analysis\n",
    "            ax4 = fig.add_subplot(224)\n",
    "            if 'volume' in pre_earnings.columns and 'open_interest' in pre_earnings.columns:\n",
    "                # Group by strike and sum volume/OI\n",
    "                strike_analysis = pre_earnings.groupby('strike').agg({\n",
    "                    'volume': 'sum',\n",
    "                    'open_interest': 'sum',\n",
    "                    'impl_volatility': 'mean'\n",
    "                }).reset_index()\n",
    "                \n",
    "                # Filter for reasonable strikes (within 20% of ATM)\n",
    "                current_price = strike_analysis['strike'].median()  # Approximate current price\n",
    "                reasonable_strikes = strike_analysis[\n",
    "                    (strike_analysis['strike'] >= current_price * 0.8) & \n",
    "                    (strike_analysis['strike'] <= current_price * 1.2)\n",
    "                ]\n",
    "                \n",
    "                if len(reasonable_strikes) > 0:\n",
    "                    ax4_vol = ax4.twinx()\n",
    "                    \n",
    "                    # Volume bars\n",
    "                    ax4.bar(reasonable_strikes['strike'], reasonable_strikes['volume'], \n",
    "                           alpha=0.6, color='blue', label='Volume')\n",
    "                    ax4.set_xlabel('Strike Price')\n",
    "                    ax4.set_ylabel('Volume', color='blue')\n",
    "                    ax4.tick_params(axis='y', labelcolor='blue')\n",
    "                    \n",
    "                    # Open Interest line\n",
    "                    ax4_vol.plot(reasonable_strikes['strike'], reasonable_strikes['open_interest'], \n",
    "                               'ro-', markersize=4, label='Open Interest')\n",
    "                    ax4_vol.set_ylabel('Open Interest', color='red')\n",
    "                    ax4_vol.tick_params(axis='y', labelcolor='red')\n",
    "                    \n",
    "                    ax4.set_title('Volume & Open Interest by Strike')\n",
    "                    ax4.legend(loc='upper left')\n",
    "                    ax4_vol.legend(loc='upper right')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "            # Additional analysis and statistics\n",
    "            self._print_surface_statistics(pre_earnings, ticker)\n",
    "    \n",
    "    def print_surface_statistics(self, pre_earnings, ticker):\n",
    "        \"\"\"\n",
    "        Print detailed statistics about the pre-earnings surface\n",
    "        \"\"\"\n",
    "        print(f\"\\n{ticker} Pre-Earnings Surface Statistics:\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        # IV statistics\n",
    "        if 'impl_volatility' in pre_earnings.columns:\n",
    "            iv_stats = pre_earnings['impl_volatility'].describe()\n",
    "            print(f\"Implied Volatility Statistics:\")\n",
    "            print(f\"  Mean: {iv_stats['mean']:.2%}\")\n",
    "            print(f\"  Median: {pre_earnings['impl_volatility'].median():.2%}\")\n",
    "            print(f\"  Std Dev: {iv_stats['std']:.2%}\")\n",
    "            print(f\"  Min: {iv_stats['min']:.2%}\")\n",
    "            print(f\"  Max: {iv_stats['max']:.2%}\")\n",
    "        \n",
    "        # Term structure analysis\n",
    "        if 'tte' in pre_earnings.columns:\n",
    "            print(f\"\\nTime to Expiration Range:\")\n",
    "            print(f\"  Min: {pre_earnings['tte'].min():.0f} days\")\n",
    "            print(f\"  Max: {pre_earnings['tte'].max():.0f} days\")\n",
    "            \n",
    "            # Average IV by expiration bucket\n",
    "            tte_buckets = pd.cut(pre_earnings['tte'], \n",
    "                               bins=[0, 7, 14, 30, 60, 90, float('inf')],\n",
    "                               labels=['0-7d', '7-14d', '14-30d', '30-60d', '60-90d', '90d+'])\n",
    "            \n",
    "            bucket_iv = pre_earnings.groupby(tte_buckets)['impl_volatility'].mean()\n",
    "            print(f\"\\nAverage IV by Expiration Bucket:\")\n",
    "            for bucket, iv in bucket_iv.items():\n",
    "                if not pd.isna(iv):\n",
    "                    print(f\"  {bucket}: {iv:.2%}\")\n",
    "        \n",
    "        # Moneyness analysis\n",
    "        if 'moneyness' in pre_earnings.columns:\n",
    "            print(f\"\\nMoneyness Distribution:\")\n",
    "            money_buckets = pd.cut(pre_earnings['moneyness'], \n",
    "                                 bins=[0, 0.9, 0.95, 1.05, 1.1, float('inf')],\n",
    "                                 labels=['Deep OTM', 'OTM', 'ATM', 'ITM', 'Deep ITM'])\n",
    "            \n",
    "            bucket_counts = pre_earnings.groupby(money_buckets).size()\n",
    "            bucket_iv = pre_earnings.groupby(money_buckets)['impl_volatility'].mean()\n",
    "            \n",
    "            for bucket in bucket_counts.index:\n",
    "                if not pd.isna(bucket_iv[bucket]):\n",
    "                    print(f\"  {bucket}: {bucket_counts[bucket]} options, Avg IV: {bucket_iv[bucket]:.2%}\")\n",
    "        \n",
    "        # Volume analysis\n",
    "        if 'volume' in pre_earnings.columns:\n",
    "            total_volume = pre_earnings['volume'].sum()\n",
    "            avg_volume = pre_earnings['volume'].mean()\n",
    "            print(f\"\\nVolume Analysis:\")\n",
    "            print(f\"  Total Volume: {total_volume:,.0f}\")\n",
    "            print(f\"  Average Volume per Option: {avg_volume:.1f}\")\n",
    "            \n",
    "            # High volume options\n",
    "            high_vol_threshold = pre_earnings['volume'].quantile(0.9)\n",
    "            high_vol_options = pre_earnings[pre_earnings['volume'] >= high_vol_threshold]\n",
    "            print(f\"  High Volume Options (>90th percentile): {len(high_vol_options)}\")\n",
    "            \n",
    "            if len(high_vol_options) > 0:\n",
    "                print(f\"  Average IV for High Volume Options: {high_vol_options['impl_volatility'].mean():.2%}\")\n",
    "        \n",
    "        # Put/Call analysis if option_type is available\n",
    "        if 'option_type' in pre_earnings.columns:\n",
    "            put_call_summary = pre_earnings.groupby('option_type').agg({\n",
    "                'impl_volatility': 'mean',\n",
    "                'volume': 'sum'\n",
    "            })\n",
    "            \n",
    "            print(f\"\\nPut/Call Analysis:\")\n",
    "            for opt_type, data in put_call_summary.iterrows():\n",
    "                print(f\"  {opt_type.upper()}s - Avg IV: {data['impl_volatility']:.2%}, Total Volume: {data['volume']:,.0f}\")\n",
    "        \n",
    "        print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7877feec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage function\n",
    "def run_earnings_iv_analysis(wrds_connection, tickers=['AAPL', 'MSFT', 'GOOGL'], \n",
    "                           start_date='2023-01-01', end_date='2024-12-31'):\n",
    "    \"\"\"\n",
    "    Convenience function to run the complete analysis\n",
    "    \n",
    "    Args:\n",
    "        wrds_connection: Active WRDS database connection\n",
    "        tickers: List of ticker symbols to analyze\n",
    "        start_date: Analysis start date\n",
    "        end_date: Analysis end date\n",
    "    \n",
    "    Returns:\n",
    "        EarningsIVDataPipeline: Configured pipeline object with results\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize pipeline\n",
    "    pipeline = EarningsIVDataPipeline(wrds_connection)\n",
    "    \n",
    "    # Run full analysis\n",
    "    success = pipeline.run_full_analysis(tickers, start_date, end_date)\n",
    "    \n",
    "    if success:\n",
    "        print(f\"\\nð Exporting results...\")\n",
    "        pipeline.export_data()\n",
    "        print(f\"\\nð Analysis complete! Results saved and pipeline ready for further exploration.\")\n",
    "    else:\n",
    "        print(f\"\\nð¥ Analysis failed. Check the logs above for details.\")\n",
    "    \n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a078b506-2c8d-4ab7-850e-331c471e6ebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading library list...\n",
      "Done\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'EarningsIVDataPipeline' object has no attribute 'run_full_analysis'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m END_DATE \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2024-12-31\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Run analysis\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m run_earnings_iv_analysis(\n\u001b[1;32m     21\u001b[0m     wrds_connection\u001b[38;5;241m=\u001b[39mdb,\n\u001b[1;32m     22\u001b[0m     tickers\u001b[38;5;241m=\u001b[39mTICKERS,\n\u001b[1;32m     23\u001b[0m     start_date\u001b[38;5;241m=\u001b[39mSTART_DATE,\n\u001b[1;32m     24\u001b[0m     end_date\u001b[38;5;241m=\u001b[39mEND_DATE\n\u001b[1;32m     25\u001b[0m )\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Access results\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mearnings_options\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m pipeline\u001b[38;5;241m.\u001b[39mdata:\n",
      "Cell \u001b[0;32mIn[5], line 21\u001b[0m, in \u001b[0;36mrun_earnings_iv_analysis\u001b[0;34m(wrds_connection, tickers, start_date, end_date)\u001b[0m\n\u001b[1;32m     18\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m EarningsIVDataPipeline(wrds_connection)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Run full analysis\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m success \u001b[38;5;241m=\u001b[39m pipeline\u001b[38;5;241m.\u001b[39mrun_full_analysis(tickers, start_date, end_date)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mð Exporting results...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'EarningsIVDataPipeline' object has no attribute 'run_full_analysis'"
     ]
    }
   ],
   "source": [
    "# Main execution block\n",
    "if __name__ == \"__main__\":\n",
    "    \"\"\"\n",
    "    Example usage - modify as needed\n",
    "    \"\"\"\n",
    "    \n",
    "    import wrds\n",
    "    \n",
    "    # Connect to WRDS\n",
    "    db = wrds.Connection(wrds_username='joycexu020113')\n",
    "    \n",
    "    # Define analysis parameters\n",
    "    #TICKERS = ['AAPL', 'MSFT', 'GOOGL', 'TSLA', 'NVDA']\n",
    "    TICKERS = ['AAPL']\n",
    "\n",
    "    START_DATE = '2023-01-01'\n",
    "    END_DATE = '2024-12-31'\n",
    "    \n",
    "    # Run analysis\n",
    "    pipeline = run_earnings_iv_analysis(\n",
    "        wrds_connection=db,\n",
    "        tickers=TICKERS,\n",
    "        start_date=START_DATE,\n",
    "        end_date=END_DATE\n",
    "    )\n",
    "    \n",
    "    # Access results\n",
    "    if 'earnings_options' in pipeline.data:\n",
    "        print(f\"Final dataset shape: {pipeline.data['earnings_options'].shape}\")\n",
    "        print(f\"Available columns: {list(pipeline.data['earnings_options'].columns)}\")\n",
    "    \n",
    "    # Close connection\n",
    "    db.close()\n",
    "    \n",
    "    print(\"Earnings IV Analysis Pipeline Loaded Successfully!\")\n",
    "    print(\"To use: create WRDS connection and call run_earnings_iv_analysis()\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4cffd3",
   "metadata": {},
   "source": [
    "\n",
    "# ð Earnings Volatility Forecasting Project\n",
    "\n",
    "**Objective**: Predict post-earnings realized volatility using pre-earnings implied volatility and option features, as motivated by Wolfe Research's paper on Unexpected Earnings Risk.\n",
    "\n",
    "**This Notebook Covers:**\n",
    "- Data filtering\n",
    "- Realized volatility computation\n",
    "- Pre-earnings implied volatility extraction\n",
    "- Simple regression and evaluation interface\n",
    "- Visualizations and case study on AAPL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f2acd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1cff361",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_realized_volatility(price_series, window=21):\n",
    "    log_returns = np.log(price_series / price_series.shift(1))\n",
    "    realized_vol = log_returns.rolling(window).std() * np.sqrt(252)\n",
    "    return realized_vol\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a757e3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def filter_option_data(df, ticker='AAPL', moneyness_range=(0.95, 1.05), \n",
    "                       maturity_range=(10, 45), min_volume=100):\n",
    "    df_filtered = df.copy()\n",
    "    df_filtered = df_filtered[df_filtered['ticker'] == ticker]\n",
    "    df_filtered = df_filtered[(df_filtered['moneyness'] >= moneyness_range[0]) &\n",
    "                              (df_filtered['moneyness'] <= moneyness_range[1])]\n",
    "    df_filtered = df_filtered[(df_filtered['days_to_expiry'] >= maturity_range[0]) &\n",
    "                              (df_filtered['days_to_expiry'] <= maturity_range[1])]\n",
    "    df_filtered = df_filtered[df_filtered['volume'] >= min_volume]\n",
    "    return df_filtered\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710a4652",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def kernel_regression(X_train, y_train, X_test, y_test, gamma=0.1, alpha=1.0):\n",
    "    model = KernelRidge(kernel='rbf', gamma=gamma, alpha=alpha)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    print(\"R^2:\", r2_score(y_test, preds))\n",
    "    print(\"RMSE:\", mean_squared_error(y_test, preds, squared=False))\n",
    "    return model, preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e43da49",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_vol_series(dates, iv, rv, earnings_date=None):\n",
    "    plt.figure(figsize=(12,6))\n",
    "    plt.plot(dates, iv, label='Implied Volatility')\n",
    "    plt.plot(dates, rv, label='Realized Volatility', linestyle='--')\n",
    "    if earnings_date:\n",
    "        plt.axvline(x=earnings_date, color='red', linestyle='--', label='Earnings')\n",
    "    plt.legend()\n",
    "    plt.title(\"IV and RV Over Time\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Volatility\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98508eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_iv_surface_slices(pre_earnings):\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    fig = plt.figure(figsize=(14, 10))\n",
    "    \n",
    "    # ATM term structure\n",
    "    ax2 = fig.add_subplot(221)\n",
    "    atm_data = pre_earnings[\n",
    "        (pre_earnings['moneyness'] >= 0.95) & \n",
    "        (pre_earnings['moneyness'] <= 1.05)\n",
    "    ]\n",
    "    if len(atm_data) > 0:\n",
    "        ts_data = atm_data.groupby('tte')['impl_volatility'].mean()\n",
    "        ax2.plot(ts_data.index, ts_data.values, 'bo-', markersize=5)\n",
    "        ax2.set_xlabel('Days to Expiration')\n",
    "        ax2.set_ylabel('Implied Volatility')\n",
    "        ax2.set_title('ATM Term Structure (Pre-Earnings)')\n",
    "\n",
    "    # Volatility smile for a specific TTE range (14â30 days)\n",
    "    ax3 = fig.add_subplot(222)\n",
    "    short_tte = pre_earnings[(pre_earnings['tte'] >= 14) & (pre_earnings['tte'] <= 30)]\n",
    "    if len(short_tte) > 0:\n",
    "        smile_data = short_tte.groupby('moneyness')['impl_volatility'].mean()\n",
    "        ax3.plot(smile_data.index, smile_data.values, 'go-', markersize=5)\n",
    "        ax3.set_xlabel('Moneyness')\n",
    "        ax3.set_ylabel('Implied Volatility')\n",
    "        ax3.set_title('Volatility Smile (TTE 14â30 Days)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
